\pagenumbering{arabic}
\chapter{Einleitung}
Seit einigen Jahren ist ein massiver \textcolor{blue}{Anstieg} an \textcolor{blue}{Datenaufkommen} zu beobachten \cite{EMC2014}. Diese Entwicklung erfordert neue Technologien und Prozesse, zum Beispiel bei der Speicherung und der Verarbeitung der Daten. Denn traditionelle Datenbanksysteme können große Datenmengen nicht immer in akzeptabler Form und Verarbeitungszeit verarbeiten \cite{Jacobs2009}. Ein zum Zweck der Verarbeitung großer Datenmengen entwickeltes Programmiermodell ist das Map-Reduce Paradigma, das 2004 erstmals publiziert wurde \cite{Dean2008}. Dieses Paradigma sieht eine massiv parallelisierte Verarbeitung von Daten vor und wird von Datenverarbeitungssystemen wie Hadoop \cite{HadoopWebsite} und Flink \cite{FlinkWebsite} implementiert.
\newline
Im Rahmen dieser Bachelorarbeit sollen ein traditioneller Ansatz und ein massiv parallelisierbarer Ansatz bei der Verarbeitung von großen Datenmengen untersucht werden. Der Vergleich beider Ansätze wird am Beispiel eines Algorithmus zur Approximierung einer Pixelzeitreihe durchgeführt. Dieser wird im Rahmen des Projekts GeoMultiSens \cite{GeoMultiSensWebsite}
 zur Analyse der Veränderung der Flora in einer geographischen Region genutzt. An die Analyse anschließend werden mithilfe des Algorithmus auf Basis der approximierten Werte Prognosen zur weiteren Entwicklung der Flora der untersuchten Region gestellt.
\newline
Es werden drei unterschiedliche Implementierungen des Algorithmus untersucht, die sich hinsichtlich der eingesetzten Technologien und Programmiersprachen unterscheiden. Die Methodik, die der Algorithmus implementiert, ist bei allen untersuchten Varianten identisch. Als Basis wird die bereits implementierte und in der Praxis genutzte Python-Implementation genutzt. Die zweite und dritte Variante werden in Flink implementiert. Diese beiden Varianten unterscheiden sich bezüglich der genutzten Programmiersprache. \textcolor{blue}{Zur Implementierung von Variante zwei wird Flinks Java-Schnittstelle genutzt, zur Umsetzung von Variante drei die Python-Schnittstelle.} Schließlich werden alle drei Varianten unter identischen Bedingungen getestet. Dies bedeutet, dass sowohl die Testumgebung als auch die Testdaten identisch sein sollen. Ausgehend von den Tests und den ermittelten Ergebnissen wird eine Bewertung der drei Implementierungsvarianten des Algorithmus vorgenommen werden.

%----------------------------------------------------------------------------------

\chapter{Grundlagen}
\section{Grundlagen der Satellitenbildanalyse}
Einführung von geo. Dingen (Koordinaten(Definition, numerische Darstellung, Umgang mit Koordinaten), Aufbereitung von Bildern (Transformieren von Bildern zur Entzerrung.), Fernerkundung etc.)

Satellitenbilder sind definiert als eine Momentaufnahme eines bestimmten geographischen Gebiets der Erde. (Detailliertere Beschreibung der Fernerkundung gemäß [DIN 18716/3]) Fernerkundungssatelliten zeichnen Satellitenbilder mithilfe verschiedener Aufnahmesysteme auf. Dies geschieht meist mutlisensoral, da dieselbe geographische Region mithilfe verschiedener Aufnahme-Systemen aufgezeichnet wird. Die Art und Qualität der Aufnahmesensoren ist dabei abhängig vom Typ des Satelliten. Die Ausgangsdaten für die Untersuchungen in dieser Bachelorarbeit wurden von Satelliten des Landsat-Satellitensystems aufgenommen. Diese nutzen in der aktuellen Generation als Abtast-Systeme Operational Land Imager (OLI) \cite{Markham2004} sowie Thermal Infrared Sensors (TIRS) \cite{Chaudhary2011}. Dabei verfügen aktuelle Landsat-Satelliten über acht Spektralkanäle, zwei Thermalkanäle und einen Panchromatischen Kanal. Spektralkanäle bezeichnen Ausschnitte aus dem elektromagnetischen Strahlungsspektrum. Die bedeutensten Spektralbereiche bei der Fernerkundung sind die des sichtbaren Lichts, des Nahen Infrarots (780 nm bis 3 µm) und des Mittleren Infrarots (3µm - 50µm). Zusätzlich nutzen Landsat-Satelliten der 8. Generation ein weiteres Infrarotband (1,36 µm - 1,38 µm), um Cirrus-Wolken zu erfassen, zwei Thermalbänder sowie ein panchromatisches Band. Dieses panchromatische Band erfasst elektromagnetische Emissionen in einem ähnlichen Bereich wie das menschliche Auge. Aufgrund des im Vergleich zu den einzelnen Farbbändern großen Spektralbereichs ermöglicht es eine höhere Auflösung als die anderen Bänder der Landsat-Satelliten.

Die von Landsat-Satelliten aufgezeichneten und übermittelten Bilder müssen jedoch vor der Nutzung für Analysen aufbereitet werden, um beispielsweise durch die Erdkrümmung hervorgerufene Einflüsse zu korrigieren. (Aufbereitung detailliert beschreiben).
 
Durch die zunehmend bessere Qualität von Satellitenbildern, die durch Fernerkundungsatelliten aufgezeichnet werden \cite{Markham2004}, können detailliertere Analysen getätigt werden. Dabei werden die aufbereiteten Satellitenaufnahmen als Ausgangspunkt genutzt. Im Fall der im Rahmen dieser Bachelorarbeit genutzten Analyse der Veränderung der Flora in einer geographischen Region werden die Ausgangsdaten mithilfe eines 

\section{Parallele Datenverarbeitungssysteme}
Um die seit mehreren Jahren massiv ansteigenden Datenmengen \cite{EMC2014} zu verarbeiten wird zunehmend eine verteilte Verarbeitung dieser Daten populär. Dazu werden mehrere Maschinen zu einem Netzwerk, einem sogenannten Cluster, zusammengeschlossen. Diese Computer wären als einzelne Maschine nicht in der Lage ein großes beziehungsweise komplexes Problem in akzeptabler Zeit zu lösen. Die Leistungsfähigkeit des Netzwerks wird jedoch nicht über die Leistung einer einzelnen Maschine sondern primär über die Menge der zusammengeschlossenen Computer gesteuert. Dies hat mehrere Vorteile gegenüber der Verarbeitung mithilfe einzelner, besonders leistungsstarker Maschinen. Die wichtigsten Vorteile parallelisierter Systeme sind ihre Skalierbarkeit sowie die Fehlertoleranz. Falls mehr Rechenleistung benötigt wird oder wenn Teile des Netzwerks nicht funktionsfähig sind lassen sich neue Maschinen kurzfristig, meist auch im laufenden Betrieb, in das bestehende Netzwerk integrieren. Bei einzelnen, sehr leistungsstarken Computern gestaltet sich beides aufgrund der abgeschlossenen Beschaffenheit der Maschine schwierig. [Quelle]

Eine \textcolor{blue}{Big-Data Anwendung} zeichnet sich durch drei Eigenschaften aus. Diese drei Charakteristika sind die Größe (engl. Volume), die Komplexität (eng. Variety) und die echtzeitnahe Verfügbarkeit sowie schnelle Verarbeitung (engl. Velocity) der Daten \cite{Laney2001}. Eine weiteres Merkmal ist die nicht garantierte Zuverlässigkeit und Einheitlichkeit der Daten (engl. veracity) \cite{Zikopoulos2012}. 
In den letzten Jahren hat sich das global produzierte Datenaufkommen massiv gesteigert. Insbesondere die zunehmende Zahl der Internetnutzer sowie die Verbreitung von Smartphones trägt zu dieser Entwicklung bei. Ebenso trägt die zunehmende Digitalisierung der Industrie sowie die zunehmende Verbreitung von Sensoren jeglicher Art zu diesem Anstieg bei. Aber auch in nicht kommerziellen Bereichen wächst die Datenmenge. Die Satellitenbilder der aktuellen Generation des Landsat-Satellitensystems produziert Aufnahmen, die dreimal soviel Speicherplatz benötigen wie die der vorigen Generation. Projekte wie das Sloan Digital Sky Survey produzieren täglich etwa 200 Gigabyte. Insgesamt werden die Datenmengen weiter massiv zunehmen. Für das Jahr 2020 wird eine weltweites Datenaufkommen von 44 Zettabyte prognostiziert \cite{EMC2014}. Aus dieser steigenden Datenmenge ergeben sich auch Folgen für Daten verarbeitende Dienste. Es müssen sehr viel mehr Daten auf einmal verarbeitet werden. Darüber hinaus sind die zu verarbeitenden Daten zunehmend vielfältiger und unstrukturierter. Die verarbeitenden Algorithmen und die Speicherstrukturen müssen also hinreichend auf unvollständige beziehungsweise fehlerhafte Datensätze reagieren können und diese trotzdem bestmöglich verarbeiten. [Quellen] [Beschreibung für velocity einfügen].
Wenn eine Anwendung eine Datenmenge verarbeitet, die mindestens einige der vier Kriterien nach \cite{Laney2001} erfüllt, gilt diese Anwendung als Bi-Data Anwendung. 


Eigenschaften von: Big Data, DBMS, Grundlagen für Flink, Erwähnung MapReduce Prinzip

\section{Programmierabstraktionen}
%Flink, Python, Parallel computing
\subsection{Apache Flink}
Eigenschaften + Operatoren in Flink

Apache Flink ist ein System[Framework], das auf eine massiv parallelisierte Verarbeitung \textcolor{green}{Vorher einführen, 2.2.1} von großen Datenmengen spezialisiert ist. Es ging \textcolor{green}{2014} [Quelle] aus Stratosphere hervor, das seit 2010[Quelle] kooperativ von Forschern verschiedener Universitäten entwickelt wurde \cite{Alexandrov2014}. Seit Januar 2015 ist Flink ein Top-Level Projekt der Apache Software Foundation \cite{ApacheFlinkBlogEntry}. 

Die Hauptkomponenten des Systems sind die Flink-Laufzeitumgebung und der Flink-Optimierer. Der Flink-Optimierer erhält einen azyklischen Graphen von Flink-Operatoren als Eingabe. Dieser wird mithilfe von Techniken der traditionellen Optimierung von relationalen Anfragen optimiert. [Weitere Details aus Stratosphere Paper?, unter welchen Gesichtspunkten wird DAG optimiert?]. Der optimierte Datenflussgraph, auch Jobgraph genannt, besteht aus mehreren, teilweise unabhängig voneinander zu verarbeitenden Arbeitsschritten. Diese können teilweise parallel bearbeitet werden [MapReduce erwähnen?]. Dieser optimierte Datenflussgraph wird an die Flink-Laufzeitumgebung weitergegeben. 

Flink erweitert das Map-Reduce Paradigma um weitere Operatoren. [Operatoren beschreiben]
\subsection{Python}
Python ist eine quelloffene und universell einsetzbare Programmiersprache, die seit 1989 existiert und fortwährend weiter entwickelt wird. Prägende Eigenschaften der Sprache sind unter anderem eine dynamische Typisierung von Variablen, eine simpel gehaltene Syntax und die Erweiterbarkeit durch Module und Bibliotheken. Es ist auch möglich Python-Code durch C- beziehungsweise C++-Bibliotheken zu erweitern \cite{Martelli2006}. Dies ermöglicht eine verkürzte Ausführungszeit eines Programms, insbesondere bei rechenintensiven Programmabschnitten. Ein Schwachpunkt von Python im Bezug auf die schnelle Verarbeitung großer Datenmengen ist die nicht auf automatisierte Parallelisierung ausgelegte Architektur. Daraus resultiert eine unzureichende Skalierbarkeit, sobald Daten, deren Größe die Arbeitsspeichergröße der ausführenden Maschine übersteigt, verarbeitet werden müssen. \textcolor{green}{(Auf weiter oben genannten Punkt der Großen Datenmengen eingehen). Bez. der Eignung zur Lösung solcher Probleme}. 

%----------------------------------------------------------------------------------

\chapter[Algorithmus zur Analyse von Pixelzeitreihen]{Beschreibung und Umsetzung des Algorithmus zur Analyse von Pixelzeitreihen}
\section[Beschreibung des Algorithmus]{Beschreibung des Algorithmus zur Analyse von Pixelzeitreihen}
Beschreibung der Vorgehensweise bei der Analyse (Zhu, SVR), Ziel der Analyse, Entwicklungsgeschichte der Analysetechnik
\section{Umsetzung des Algorithmus mit Apache Flink}
\subsection{Nutzung der Java-Programmierschnittstelle}
\subsection{Nutzung der Python-Programmierschnittstelle}
\section{Umsetzung des Algorithmus in Python}
%Einordnung als Big-Data Problem (Einordnung am GfZ bei GeoMultiSens)
Die Analyse von Satellitenbildern erfordert die Verarbeitung großer Mengen komplexer Rohdaten, \textcolor{green}{die nahezu in Echtzeit verfügbar sind}. Aufgrund dieser Charakteristika handelt es sich bei dieser Analyse um ein \textcolor{blue}{Big-Data Problem}. Denn alle vier Kriterien, die ein solches charakterisieren sind erfüllt.
\newline
Bei der Analyse von Satellitenbildern sind die Merkmale Datengröße und Datenkomplexität sowie die schnelle Verarbeitung der Daten von Bedeutung. Abhängig von der Anzahl der genutzten Bilder sind die zu verarbeitenden Datenmengen sehr groß. Ein Bild besitzt im Regelfall abhängig vom Satellitenmodell, das die Aufnahme gemacht hat, eine Größe von 750 Megabyte bis zu 1,5 Gigabyte. Um eine Entwicklung zu untersuchen werden jedoch viele dieser Bilder in die Untersuchung mit einbezogen, so dass die zu verarbeitende Datenmenge kontinuierlich ansteigt. Dieser kontinuierliche Anstieg entsteht dadurch, dass aktuell mehrere Satelliten mit der Fernerkundung der Erde fortfahren und so in kurzen Intervallen neue Bilder zur Verfügung stehen, die im Rahmen der Analyse verwendet werden sollen. \textcolor{green}{Quelle}.
%Big Data + Eigenschaften,



%Datenstrom mit Flink Operatoren
\begin{tikzpicture}[>=latex']
        \tikzset{block/.style= {draw, rectangle, align=center,minimum width=2cm,minimum height=1cm},
        rblock/.style={draw, shape=rectangle,rounded corners=1.5em,align=center,minimum width=2cm,minimum height=1cm},
        input/.style={ % requires library shapes.geometric
        draw,
        trapezium,
        trapezium left angle=60,
        trapezium right angle=120,
        minimum width=1cm,
        align=center,
        minimum height=1cm
    },
        }
        \node [rblock]  (start) {Input data};
        %Filter the data
        \node [block, below =1cm of start, label={[name=l] Filter the data}, draw] (filterDataInner) {filter('valid')};
        \node [fit=(filterDataInner) (l), draw] (filterDataOuter) {};
        %Group the data
        \node [block, below =1cm of filterDataOuter, label={[name=l] Group the filtered data}, draw] (groupDataInner) {groupBy('geographic position(maybe as a tile)')};
        \node [fit=(groupDataInner) (l), draw] (groupDataOuter) {};
        %Sort every grouped dataSet
        \node [block, below =1cm of groupDataOuter, label={[name=l] Sort every grouped dataSet}, draw] (sortDataInner) {sortPartition('time')};
        \node [fit=(sortDataInner) (l), draw] (sortDataOuter) {};
        %Approx the missing data
        \node [block, below = 1cm of sortDataOuter, label={[name=l] Approx. the missing data}, draw] (approximateDataInner) {groupReduce()};
        \node [fit=(approximateDataInner) (l), draw] (approximateDataOuter) {};
        %Predict the future data
        \node [block, below = 1cm of approximateDataOuter, label={[name=l] Predict the future data}, draw] (predictDataInner) {groupReduce()};
        \node [fit=(predictDataInner) (l), draw] (predictDataOuter) {};
        %Sink the data
        \node [rblock, below = 1cm of predictDataOuter, draw] (end) {Sink};

        \node [coordinate, below right =1cm and 1cm of start] (right) {};  %% Coordinate on right and middle
        \node [coordinate,above left =1cm and 1cm of start] (left) {};

%% paths
        \path[draw,->] (start) edge (filterDataOuter)
                    (filterDataOuter) edge (groupDataOuter)
                    (groupDataOuter) edge (sortDataOuter)
                    (sortDataOuter) edge (approximateDataOuter)
                    (approximateDataOuter) edge (predictDataOuter)
                    (predictDataOuter) edge (end)
                    ;
\end{tikzpicture}

%Minimal diagram example
%\begin{tikzpicture}[nodes=draw]
%    \node [label=label1,draw] (node1) {Node1};
%\end{tikzpicture}

%----------------------------------------------------------------------------------

\chapter{Evaluierung}
%Korrektheit, Performant, welche Impl. anderen überlegen [bei welchen Gesichtspunkten]
\section{Versuchsbeschreibung}
Beschreibung + Begründung für meine Versuchsbedingungen
\section{Auswertung}
Beschreibung und Bewertung der Ergebnisse meiner Untersuchungen

\chapter{Fazit}
Fazit und Ausblick
z.b. Vergleich mit anderen Untersuchungen

